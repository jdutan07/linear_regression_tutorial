{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#import regression (machine learning) module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT   GPA\n",
       "0  1714  2.40\n",
       "1  1664  2.52\n",
       "2  1760  2.54\n",
       "3  1685  2.74\n",
       "4  1693  2.83"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load\n",
    "data = pd.read_csv('1.01. Simple linear regression.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the machine learning algorithm will find the optimal coefficients of a linear regression model, that when given an SAT score, best predict the GPA of a student.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent variable: 'SAT'\n",
    "x = data['SAT']\n",
    "\n",
    "#dependent variable: 'GPA'\n",
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#useful to check the shapes of the features\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**inputs and targets are both vectors of length 84**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn **prefers 2D arrays for its INPUTS, not 1D arrays.** \n",
    "\n",
    "# A MATRIX IS A 2D OBJECT, ALSO KNOW AS A 2D ARRAY!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to feed x to sklearn, it should be a 2D array (a matrix)\n",
    "# Therefore, we must reshape it \n",
    "# Note that this will not be needed when we've got more than 1 feature (as the inputs will be a 2D array by default)\n",
    "\n",
    "# x_matrix = x.values.reshape(84,1)\n",
    "#NOTE: we are not changing anything, but the dimenstionality\n",
    "#its (-1,1) NOT (84,1) because the program works better this way. \n",
    "x_matrix = x.values.reshape(-1,1) \n",
    "\n",
    "# Check the shape just in case\n",
    "x_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** regarding reshaping the feature into a 2D object is because it was 1D. This is only an issue we had to do for a **SIMPLE LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn takes full advantage of the object-oriented capabilities of Python and works a lot with very well written classes. More often than not, we would need to create an object or an instance of the given class**\n",
    "\n",
    "So in this case, we're letting **reg be equal to LinearRegression()**. After executing that line, reg will be an instance of the linear regression class. Afterwards, all you need to do is fit the regression. \n",
    "\n",
    "The fit order is **very important**, must be (inputs,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression itself\n",
    "Full documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by creating a linear regression object\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The whole learning process boils down to fitting the regression\n",
    "# Note that the first argument is the independent variable, while the second - the dependent (unlike with StatsModels)\n",
    "reg.fit(x_matrix,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't know why, but the **reg.fit(x_matrix,y)** on udemy produces **LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)**, which is different from what i get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**copy_X = True** --> when its set to true it copies the inputs before fitting them. This is a safety net against normalization and other transformations that can be done by SK Learn while creating an algorithm. If you remember in our stats models lectures we would create copies of data frames every now and then. SK learn takes to care of that automatically.\n",
    "\n",
    "**fit_intercept=True** --> in stats models, we had to manually add a constant. The fit intercept parameter takes care precisely of that. If you don't want an intercept you can just set it to false.\n",
    "\n",
    "**n_jobs=1** --> is a parameter used when we want to parallelize routines. By default, only one CPU is used. For this simple example we won't see a difference no matter the number  of jobs we set. However, if you work on problems with lots and lots of data and have more than one CPU available, you can take advantage of this parameter by setting it to 2, 3, 5, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.17249439])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict([[1750]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
